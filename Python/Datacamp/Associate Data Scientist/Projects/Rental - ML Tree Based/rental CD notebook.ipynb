{"cells":[{"source":"A DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1729636028315,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","lastExecutedByKernel":"ef08b76b-cdf4-49e2-8eb8-cfdb66d6c9e9"},"id":"a7ede566-910a-445c-b11a-68d192ac8506","cell_type":"code","execution_count":33,"outputs":[]},{"source":"- [x] Read in the csv file rental_info.csv using pandas.\n- [x] Create a column named \"rental_length_days\" using the columns \"return_date\" and \"rental_date\", and add it to the pandas DataFrame. This column should contain information on how many days a DVD has been rented by a customer.\n- [X] Create two columns of dummy variables from \"special_features\", which takes the value of 1 when:\n- [X] The value is \"Deleted Scenes\", storing as a column called \"deleted_scenes\".\n- [X] The value is \"Behind the Scenes\", storing as a column called \"behind_the_scenes\".\n- [x] Make a pandas DataFrame called X containing all the appropriate features you can use to run the regression models, avoiding columns that leak data about the target.\n- [x] Choose the \"rental_length_days\" as the target column and save it as a pandas Series called y.\n\nEDA:\n- [x] no null, all ranges look reasonable\n- [x] datatypes: need to convert into pd.DateTime for 'return_date' and 'rental_date'\n- [x] special_features need to be dumified","metadata":{},"cell_type":"markdown","id":"f7427e62-0905-4d7a-84e6-e3a7bb89b374"},{"source":"from thefuzz import process\n\ndef create_binary_columns(row, string1, string2):\n    \"\"\"\n    Given row it will find if string is in row, or string2, or both/neither using binary columns\n    \n    Arguments:\n    row: row of pd\n    string1: str\n    string2: str\n    \n    Returns \n    pd.Series of string1, string2\n    \"\"\"\n    string1_bool = 1 if string1 in row else 0\n    string2_bool = 1 if string2 in row else 0\n    \n    return pd.Series([string1_bool, string2_bool])\n\nrental_df = pd.read_csv(\"rental_info.csv\", parse_dates=['rental_date','return_date'])\nrental_df['rental_length_days'] = (rental_df['return_date'] - rental_df['rental_date']).dt.total_seconds() / 86400\n\n# Apply the function and create new columns\nrental_df[['deleted_scenes', 'behind_the_scenes']] = rental_df['special_features'].apply(create_binary_columns,                                                        args=('Deleted Scenes', 'Behind the Scenes'))\n\nrental_df.groupby('special_features')[['deleted_scenes', \n                                       'behind_the_scenes']].value_counts()","metadata":{"executionCancelledAt":null,"executionTime":2195,"lastExecutedAt":1729636030510,"lastExecutedByKernel":"ef08b76b-cdf4-49e2-8eb8-cfdb66d6c9e9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from thefuzz import process\n\ndef create_binary_columns(row, string1, string2):\n    \"\"\"\n    Given row it will find if string is in row, or string2, or both/neither using binary columns\n    \n    Arguments:\n    row: row of pd\n    string1: str\n    string2: str\n    \n    Returns \n    pd.Series of string1, string2\n    \"\"\"\n    string1_bool = 1 if string1 in row else 0\n    string2_bool = 1 if string2 in row else 0\n    \n    return pd.Series([string1_bool, string2_bool])\n\nrental_df = pd.read_csv(\"rental_info.csv\", parse_dates=['rental_date','return_date'])\nrental_df['rental_length_days'] = (rental_df['return_date'] - rental_df['rental_date']).dt.total_seconds() / 86400\n\n# Apply the function and create new columns\nrental_df[['deleted_scenes', 'behind_the_scenes']] = rental_df['special_features'].apply(create_binary_columns,                                                        args=('Deleted Scenes', 'Behind the Scenes'))\n\nrental_df.groupby('special_features')[['deleted_scenes', \n                                       'behind_the_scenes']].value_counts()","outputsMetadata":{"0":{"height":501,"type":"dataFrame"}}},"cell_type":"code","id":"9c704fdb-5b87-4da9-a6f9-91b3cd560f9c","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"special_features","type":"string"},{"name":"deleted_scenes","type":"integer"},{"name":"behind_the_scenes","type":"integer"},{"name":"0","type":"integer"}],"primaryKey":["special_features","deleted_scenes","behind_the_scenes"],"pandas_version":"1.4.0"},"data":{"0":[1108,1035,1023,1078,1101,1011,1089,1122,772,1047,1308,983,916,1129,1139],"special_features":["{\"Behind the Scenes\"}","{\"Deleted Scenes\",\"Behind the Scenes\"}","{\"Deleted Scenes\"}","{Commentaries,\"Behind the Scenes\"}","{Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}","{Commentaries,\"Deleted Scenes\"}","{Commentaries}","{Trailers,\"Behind the Scenes\"}","{Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}","{Trailers,\"Deleted Scenes\"}","{Trailers,Commentaries,\"Behind the Scenes\"}","{Trailers,Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}","{Trailers,Commentaries,\"Deleted Scenes\"}","{Trailers,Commentaries}","{Trailers}"],"deleted_scenes":[0,1,1,0,1,1,0,0,1,1,0,1,1,0,0],"behind_the_scenes":[1,1,0,1,1,0,0,1,1,0,1,1,0,0,0]}},"total_rows":15,"truncation_type":null},"text/plain":"special_features                                              deleted_scenes  behind_the_scenes\n{\"Behind the Scenes\"}                                         0               1                    1108\n{\"Deleted Scenes\",\"Behind the Scenes\"}                        1               1                    1035\n{\"Deleted Scenes\"}                                            1               0                    1023\n{Commentaries,\"Behind the Scenes\"}                            0               1                    1078\n{Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}           1               1                    1101\n{Commentaries,\"Deleted Scenes\"}                               1               0                    1011\n{Commentaries}                                                0               0                    1089\n{Trailers,\"Behind the Scenes\"}                                0               1                    1122\n{Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}               1               1                     772\n{Trailers,\"Deleted Scenes\"}                                   1               0                    1047\n{Trailers,Commentaries,\"Behind the Scenes\"}                   0               1                    1308\n{Trailers,Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}  1               1                     983\n{Trailers,Commentaries,\"Deleted Scenes\"}                      1               0                     916\n{Trailers,Commentaries}                                       0               0                    1129\n{Trailers}                                                    0               0                    1139\ndtype: int64"},"metadata":{},"execution_count":34}],"execution_count":34},{"source":"- [x] Create X and y df\n- [ ] Split data into X_train,...","metadata":{},"cell_type":"markdown","id":"972a6aa7-d6f0-41e8-9b5e-43755afde2ea"},{"source":"from sklearn.model_selection import train_test_split\nSEED = 9\n\nrental_df.head()\n\nfeatures = [\n    \"amount\",\n    \"release_year\",\n    \"rental_rate\",\n    \"length\",\n    \"replacement_cost\",\n    \"NC-17\",\n    \"PG\",\n    \"PG-13\",\n    \"R\",\n    \"deleted_scenes\",\n    \"behind_the_scenes\",\n    \"amount_2\",\n    \"length_2\",\n    \"rental_rate_2\"\n]\nX_df = rental_df[features]\n\ny_df = rental_df['rental_length_days']\n\nprint(X_df.shape)\nX_train, X_test, y_train, y_test = train_test_split(X_df,\n                                   y_df,\n                                   test_size = 0.2, # size of test data\n                                   random_state = SEED)","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1729636030563,"lastExecutedByKernel":"ef08b76b-cdf4-49e2-8eb8-cfdb66d6c9e9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import train_test_split\nSEED = 9\n\nrental_df.head()\n\nfeatures = [\n    \"amount\",\n    \"release_year\",\n    \"rental_rate\",\n    \"length\",\n    \"replacement_cost\",\n    \"NC-17\",\n    \"PG\",\n    \"PG-13\",\n    \"R\",\n    \"deleted_scenes\",\n    \"behind_the_scenes\",\n    \"amount_2\",\n    \"length_2\",\n    \"rental_rate_2\"\n]\nX_df = rental_df[features]\n\ny_df = rental_df['rental_length_days']\n\nprint(X_df.shape)\nX_train, X_test, y_train, y_test = train_test_split(X_df,\n                                   y_df,\n                                   test_size = 0.2, # size of test data\n                                   random_state = SEED)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"2ed4540a-4b0b-401f-8dc1-7d6ea8f8c772","outputs":[{"output_type":"stream","name":"stdout","text":"(15861, 14)\n"}],"execution_count":35},{"source":"- Regression Model\n- MSE - 3","metadata":{},"cell_type":"markdown","id":"b0e66419-787e-4cf8-a3e7-8cb8728bda09"},{"source":"from sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nparams_dt = {\n  'max_depth' : [3,4,5,6],\n  'min_samples_leaf': [0.04,0.06,0.08,0.1,0.12],\n  'max_features': ['auto','sqrt','log2']\n}\n\ndt = DecisionTreeRegressor(random_state=9)\ngrid_dt = GridSearchCV(estimator = dt,\n                       param_grid = params_dt,\n                       scoring = 'neg_mean_squared_error',\n                       cv = 3,\n                       n_jobs = -1,\n                       verbose = 1)\n\ngrid_dt.fit(X_train, y_train)\n\nbest_hyperparams = grid_dt.best_params_\nbest_CV_score = grid_dt.best_score_\n\nbest_model = grid_dt.best_estimator_\nbest_mse = -best_CV_score\n\nprint(\"Best Hyperparameters:\", best_model)\nprint(\"Best Cross-Validation Score:\", best_mse)\n","metadata":{"executionCancelledAt":null,"executionTime":365,"lastExecutedAt":1729636030928,"lastExecutedByKernel":"ef08b76b-cdf4-49e2-8eb8-cfdb66d6c9e9","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nparams_dt = {\n  'max_depth' : [3,4,5,6],\n  'min_samples_leaf': [0.04,0.06,0.08,0.1,0.12],\n  'max_features': ['auto','sqrt','log2']\n}\n\ndt = DecisionTreeRegressor(random_state=9)\ngrid_dt = GridSearchCV(estimator = dt,\n                       param_grid = params_dt,\n                       scoring = 'neg_mean_squared_error',\n                       cv = 3,\n                       n_jobs = -1,\n                       verbose = 1)\n\ngrid_dt.fit(X_train, y_train)\n\nbest_hyperparams = grid_dt.best_params_\nbest_CV_score = grid_dt.best_score_\n\nbest_model = grid_dt.best_estimator_\nbest_mse = -best_CV_score\n\nprint(\"Best Hyperparameters:\", best_model)\nprint(\"Best Cross-Validation Score:\", best_mse)\n","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"d71a2ea3-7d50-41ac-8a2d-12dd158a3cea","outputs":[{"output_type":"stream","name":"stdout","text":"Fitting 3 folds for each of 60 candidates, totalling 180 fits\nBest Hyperparameters: DecisionTreeRegressor(max_depth=6, max_features='auto', min_samples_leaf=0.04,\n                      random_state=9)\nBest Cross-Validation Score: 2.3072463864816437\n"}],"execution_count":36}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}